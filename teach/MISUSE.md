## A Critical Analysis: Potential Misuse of LLMs in Educational Settings

A warning bears repeating--one that many might find redundant but experience
suggests is necessary--particularly as social media demonstrates sophisticated
strategies for cultivating user dependency on products and services.
Let us examine this perspective.


__Over-Reliance and Erosion of Fundamental Skills__

- *The Parallel.* Just as companies strategically cultivate customer loyalty
  and repeat business, students may develop an excessive dependence on LLMs
  for generating text, answering questions, and even formulating ideas.

- *The Educational Impact.* This dependence potentially undermines the development
  of crucial foundational skills including critical thinking, independent research,
  effective writing, and information synthesis abilities. When students routinely
  outsource these cognitive processes to LLMs, their own capabilities in these
  domains may deteriorate. They may struggle to articulate original thoughts without
  the assistance of AI-generated content.


__The Illusion of Understanding and Superficial Learning__

- *The Parallel.* Marketing frequently emphasises creating favourable perceptions
  of products, sometimes without substantial underlying value. Similarly, LLMs can
  produce sophisticated-sounding text that conceals a student's genuine lack of
  understanding of core concepts.

- *The Educational Impact.* Students submitting AI-generated work may receive
  favourable grades, creating a deceptive sense of achievement. This superficial
  engagement with material leads to knowledge gaps and inhibits deep learning.
  Students may produce plausible answers without truly comprehending the
  "why" or "how" behind them.


__Plagiarism and Academic Dishonesty on an Unprecedented Scale__

- *The Parallel.* Although not directly analogous to customer retention strategies,
  LLMs' capacity to generate original-sounding content makes plagiarism more accessible
  and potentially more difficult to detect.

- *The Educational Impact.* The boundary between legitimate AI assistance (such as
  brainstorming or editing) and academic dishonesty (submitting AI-generated work
  as one's own) becomes increasingly indistinct. This challenges *conventional assessment*
  methods and raises significant ethical concerns regarding academic integrity.


__Bias and the Reinforcement of Existing Inequalities__

- *The Parallel.* Algorithms employed in marketing can perpetuate existing data biases,
  resulting in targeted advertising that reinforces societal inequalities. Similarly,
  LLMs trained on vast text corpora may contain inherent biases related to gender, race,
  culture, and other dimensions.

- *The Educational Impact.* Students heavily relying on LLMs risk unconsciously absorbing
  and perpetuating these biases in their work. Furthermore, disparate access to advanced
  AI tools may exacerbate existing educational inequities. Students with greater resources
  may gain unfair advantages.


__The "Optimisation" of Learning Towards LLM Capabilities__

- *The Parallel.* Just as companies optimise their offerings to align with customer preferences
  and data trends, educational practices might inadvertently shift toward favouring tasks at
  which LLMs excel, potentially neglecting other vital aspects of learning.

- *The Educational Impact.* This could result in curriculum narrowing and assessment method
  constraints, prioritising rote memorisation and information retrieval (where LLMs excel)
  over creativity, critical analysis, and nuanced argumentation (domains where human intellect
  maintains significant advantages).

In this context, I also observe that educational assessment already risks becoming an optimisation
problem, where instruction is tailored to maximise test performance rather than foster genuine learning.


### Connecting to Social Media and Customer Binding

The techniques employed to maintain user engagement (including personalised content, instant
gratification, and algorithmic feeds) parallel how students interact with LLMs. The efficiency
and immediacy with which LLMs provide answers can create dependency, potentially discouraging
the more challenging yet ultimately more rewarding process of independent learning and discovery.

In conclusion, while LLMs offer tremendous potential to enhance education, acknowledging these
potential misuses is crucial for developing strategies promoting responsible and ethical integration
of these tools. Educators must foster critical engagement with AI-generated content and emphasise
developing fundamental skills that remain essential for authentic learning and intellectual growth.

The LLM should not be reduced to a mere teaching machine or a reinforcement tool.


### Behaviourism and the "Machine Teacher" of the 1950s–60s

The concept of automated teaching originated at least as early as the 1920s and 30s, but gained
significant momentum in the 1950s and 60s, particularly through B.F. Skinner, a prominent psychologist
and behaviourist.

Skinner developed "teaching machines," devices designed to present educational material incrementally,
providing immediate reinforcement for correct responses. Students followed carefully structured
pathways through content--stimulus and response. Though mechanical, these devices embodied clear
pedagogical assumptions: learning as conditioning, with optimal student progress achieved through
reinforcement of correct behaviours.

Skinner's teaching machine was explicitly modelled on his operant conditioning theories: learning
conceptualised as behaviour modification.[^skin1]

[^skin1]: Skinner, B. F. (1954). The science of learning and the art of teaching.
*Harvard Educational Review*, 24(2), 86–97. 

Particularly incisive criticism of this model came from educators and philosophers who identified
it as dehumanising. The student was effectively reduced to a laboratory subject--stimulus, response,
reward. This reductionist approach to learning disregards the rich interpretive, social, and creative
dimensions of human cognition.


### LLMs and the Risk of Behaviourist Revival

The contemporary concern is that LLMs, if implemented simplistically--as quiz generators, essay graders,
or automated content-delivery systems--risk resurrecting this behaviourist legacy with more sophisticated
technology. When students merely "consume" and "respond" to LLM prompts, we recreate the input-output
paradigm of Skinner's machines.

Problems with this approach:
- Passive learning: Students become recipients of content rather than active agents in knowledge construction.
- Depersonalisation: Learning devolves into a transactional process, sacrificing the relational, dialogic essence of education.
- Diminished critical reflection: LLMs provide rapid, seemingly authoritative answers that may discourage deeper
  questioning or comfort with uncertainty--essential elements of authentic learning.

Though stark, this perspective suggests viewing "the student as a subject of experimentation," or "the student as a rat."

The phrase "automated teacher" evokes a historically loaded instructional model long critiqued by
education theorists. While LLMs offer genuinely innovative affordances, they risk replicating the
mechanistic limitations of behaviourism if framed primarily as tools for content delivery or student
compliance.

Their true potential lies in facilitating exploration, conversation, and reflection. Used effectively,
they transcend Skinner's teaching machines[^skin2]--functioning instead as customisable mentors or
intellectual partners, offering novel approaches to stimulate rather than substitute the human
dimensions of learning.

[^skin2]: Skinner, B. F. (1968). The technology of teaching. Appleton-Century-Crofts.


## The Technology of AI/ML

Artificial Intelligence, as a scientific field, is characterised by a diversity of technological
approaches aimed at enabling machines to perform tasks traditionally requiring human intelligence.
It is a patchwork of methods, historical developments, and shifting priorities, marked by competing
strategies for engineering intelligent behaviour. In this collection, we trace some distinct
yet interconnected technological paths within AI: the symbolic manipulation of
*[GOFAI](./gofai/) (Good Old-Fashioned Artificial Intelligence)*, the modern statistical
and data-driven techniques of *[machine learning](./ml/)*, a conceptual but rigorously
specified engineering approach embodied by the work of *John von Neumann on
[self-replicating machines](./replicate/)*, and an example of a more philosophical or conceptual
strand anchored by the work of David E. Stanley and others interested in [discovery](./discovery/)
and the nature of intelligent behaviour.


Dating back to the mid-20th century, von Neumann's abstract models, particularly his universal
constructor in the cellular automaton, explored the fundamental logical and mechanical requirements
for a system to not only construct another entity but to reproduce itself and, crucially,
to allow for the possibility of increasing complexity through a process analogous to evolution.
This line of inquiry, focused on the engineering of *autonomy and self-organisation* in
artificial systems, deeply influences contemporary discussions around recursive self-improvement
(RSI) and the long-term potential for highly autonomous AI technologies.

GOFAI represents the early promise that intelligence could be engineered through formal logic,
planning systems, and neatly packaged rules. Rooted in cognitive science and early computer
science, this tradition aspired to model human reasoning in explicit, inspectable structures.
Though now often overshadowed by data-driven techniques, GOFAI remains foundational--its legacy
persists in knowledge representation, planning, and the pursuit of explainable AI.

By contrast, the contemporary field of machine learning, particularly its statistical and neural
approaches, has reshaped AI into a discipline less concerned with internal reasoning and more
with external performance. Here, systems learn from data rather than being explicitly programmed.
The emphasis shifts from knowing to fitting, from designed structure to emergent behaviour.
The second part of this material surveys a variety of learning algorithms, each with its own
trade-offs and assumptions about the nature of generalisation.

Finally, the section on discovery returns us to a more reflective stance. Drawing on ideas from
philosophy of science and cognitive development, it asks how novelty and structure arise--not
only in artificial agents but also in our understanding of intelligence itself. In the spirit
of Stanley and others, this material resists premature closure and invites a broader conversation
about what AI can be, beyond performance benchmarks or narrow definitions.


*The themes are not meant to be exhaustive. It is a map drawn from one perspective,
and you are encouraged to redraw it as you read, challenge, and explore. AI, after all, is not
only about building machines that learn or reason, but also about how we choose to describe,
formalise, and imagine intelligence in the first place.*




MAYBE LATER:

*Embodied AI/Robotics:*
AI systems integrated with physical bodies (robots) and interact with the real world.
Specific hardware, sensing, actuation, and control algorithms that are different
from purely software-based AI.

*Distributed AI/Multi-Agent Systems:*
This is a technological approach where intelligence emerges from the interaction of multiple,
often simpler, AI agents working together, sometimes in a decentralised fashion.

*Specialised Hardware for AI (e.g., GPUs, TPUs, neuromorphic chips):*
The development of specialized computing hardware
designed to accelerate AI computations.


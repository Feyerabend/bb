
## The Technological Condition

In 1997, the world stood on the cusp of a digital revolution, a moment when computers and programming
were transitioning from niche tools of academia and industry to ubiquitous forces reshaping everyday
life. "The Technological Condition," was a lecture I held at Reykjavik, Iceland 1997 under the auspices
of The Nordic Summer University.

It emerges against this backdrop: a period marked by the rise of personal computing, the internet's
nascent mainstream adoption, and the accelerating pace of software innovation. Written at a time when
Pentium processors powered desktop PCs, Windows 95 reigned supreme, and HTML was still in its infancy,
the paper reflects an era of both optimism and uncertainty about technology's trajectory, particularly
in the realm of computation.

The late 1990s were a pivotal time for computers and programming. The release of Java in 1995 had
introduced a platform-independent language that promised "write once, run anywhere," fuelling dreams
of interoperable software ecosystems. Meanwhile, the dot-com bubble was inflating, driven by speculative
fervour over internet technologies, even as dial-up modems limited most users to 56 kbps connections.
Programmers were grappling with the shift from procedural paradigms (like C) to object-oriented
approaches (like C++ or indeed Java), laying the groundwork for the complex systems that would define
the 21st century. This was also the year IBM's Deep Blue defeated chess grandmaster Garry Kasparov,
a symbolic milestone hinting at the potential of artificial intelligence--a field then confined to
expert systems and rudimentary neural networks, far from the machine learning juggernauts of 2025.

"The Technological Condition" slots into this milieu as a reflective pause amid rapid change. It
emerged from a growing awareness that computers were not merely tools but catalysts of societal
transformation, challenging human agency, ethics, and economic structures. In 1997, programming
was still a craft bridging hardware constraints and human ambition--think Y2K bug, a looming
crisis born from shortsighted code decisions, or the open-source movement gaining traction with
Linux, hinting at collaborative futures. The paper's philosophical bent suggests it wrestles with
these developments, questioning how the logic of code and the power of processors might reshape the
human condition.

Relationally, the document connects to computers and programming as both subject and metaphor. The rise
of the internet--a decentralised network mirroring the distributed thinking of its time--parallels
the paper's interest in systems and their unintended consequences. Programming, with its emphasis
on control and abstraction, offers a lens for exploring technology's broader implications, from
automation's promise to its ethical pitfalls. For a 1997 audience, this might have evoked contemporary
debates: Could software outpace our ability to govern it? How would human values translate into
lines of code? These questions, rooted in the era's technological fabric, position the paper as a
bridge between the concrete realities of 1990s computing and the abstract concerns of philosophy.

From a 2025 perspective, revisiting this work it captures a moment when computers were still shedding
their industrial skin, and programming was poised to redefine creativity and power.

I generated a NotebookLM which compares my paper with Hanna Arendt's *The Human Condition* 1958. 
The Human Condition, originally published in 1958, offers a profound examination of humanity's
active life and its changing circumstances, especially in light of technological advancements.
The book considers how modern society has redefined fundamental human activities such as labour,
work, and action, impacting our political and social existence. This edition includes an insightful
introduction by Margaret Canovan, highlighting the enduring relevance of Arendt's analysis. The
text explores the distinction between the public and private realms and the implications of their
evolving relationship for human freedom and the common world. Ultimately, the work encourages
a reconsideration of the essential aspects of human existence in the modern age.

[NotebookLM on Arendt & my paper](./ARENDT.wav).

*There is also an element of circularity to consider here: large language models (LLMs) analysing, interpreting,
and generating content about other LLMs. This raises the question of whether such self-referential cycles
could become a problem in future datasets, as they increasingly drift away from original sources and
human-authored material. Over time, will the creative aspect of content generation become further detached
from human input as interactivity between LLMs and other generative AI systems intensifies? If these models
continue to train on AI-generated data rather than human-created sources, could this lead to a gradual
erosion of originality, innovation, or even a distortion of "knowledge" itself? Whatever that might then be
.. Your thoughts on this?*


### Questions

- *Historical Context*: How might the technological limitations of 1997 (e.g. slow internet, basic AI)
  have shaped the author's perspective on computers and programming compared to today's capabilities?

- *Programming as Power*: In what ways does programming reflect human values or biases, and how might
  this have been perceived in 1997 versus 2025?

- *Ethics and Innovation*: Should programmers in 1997 have anticipated issues like AI ethics or digital
  privacy, or were those concerns too distant to foresee?

- *Societal Impact*: How do you think the shift from individual programmers to large tech corporations
  (post-1997) has altered the "technological condition" the paper explores?

- *Future Gazing*: If you were writing this paper in 1997, what predictions would you have made about
  computers and programming by 2025, and how accurate do you think they'd be?


#### Fruitful Debate Topic for Today (2025)

- *Debate Question*: "Should AI systems be programmed with universal ethical constraints, or should their
  ethics adapt to the cultural and contextual diversity of their users?"

- *Why It's Fruitful*: This debate ties directly to the paper's implied concern with technology serving
  humanity rather than dictating behaviour. In 1997, AI was somewhat of a theoretical frontier, but today,
  with LLM models deployed globally, the question of ethical programming is urgent. It pits universalist
  ideals (e.g., a standardised AI ethics code) against relativist views (e.g., culturally specific AI
  behaviours), echoing 1990s debates about globalisation and technology's homogenising effects. Students
  could explore trade-offs: consistency versus inclusivity, control versus autonomy--all resonant with
  the paper's themes and today's AI landscape.


#### Thought Experiments for Exploration

- The 1997 AI Takeover: Imagine it's 1997, and a primitive AI like Deep Blue gains sentience, escapes
  IBM's labs, and begins rewriting its own code. How might society and programmers of that era respond,
  given their tools and mindset? What does this reveal about the "technological condition" then versus now?
    * Benefit: Tests assumptions about control, preparedness, and the pace of technological change
      between 1997 and 2025.

- The Programmer's Dilemma: You're a coder in 1997 tasked with designing software that could run for decades
  (e.g., avoiding Y2K-like flaws). You must choose between prioritising immediate functionality or long-term
  adaptability, knowing future consequences are unpredictable. What do you pick, and why?
    * Benefit: Encourages reflection on foresight, responsibility, and the tension between short-term gains
      and long-term impacts--core to the paper's ethos.

- The Internet Without Google: Picture 1997's internet evolving without the rise of centralised search engines
  (Google launched in 1998!). How would a decentralised, programmer-driven web alter the "technological condition"
  by 2025? Would it be more democratic or chaotic?
    * Benefit: Probes the role of structure versus freedom in tech ecosystems, connecting to the paper's systemic
      concerns and 1990s optimism about networks.

### Addendum: Some (Personal) Reflections on AI

In 1984, I attended The Second Logic Programming Conference in Uppsala. At the time, I had only been at the
university since 1982, studying theoretical philosophy (formal logic). I was highly optimistic--perhaps overly
so--about the future of computers, programming, computing in general, and, of course, AI.

Here are Google NotebookLM's reflections on my experience, interwoven with historical perspectives on AI.
Download [podcast](REFLECTIONS.wav) in WAVE-format.

*Discussion:* Explore the history of AI and how it connects to today. Not necssarily starting from the podcast.

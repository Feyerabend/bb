
## The Debate Over Deskilling and AI in Programming: A Balanced Perspective

The rise of AI coding assistants and low-code platforms has sparked an intense
debate about the future of software development. On one side, proponents argue
we're witnessing a positive transformation that will elevate the profession.
On the other, critics warn of a dangerous erosion of fundamental skills.
The truth probably lies somewhere in between, with both perspectives offering
valid insights worth examining.


### The Case for Optimism

Those who embrace AI-assisted development make a compelling economic argument
rooted in scarcity. The technology sector faces a fundamental imbalance where
demand for software vastly outpaces the supply of qualified engineers. Low-code
platforms and AI tools aren't primarily about replacing developers but about
addressing this bottleneck. By empowering "citizen developers" and automating
repetitive tasks, these tools expand the effective workforce while freeing
experienced developers from mundane work.

The financial data supports this optimistic view. Developers who adopt low-code
platforms earn higher salaries, with 72% making over $100,000 compared to 64%
of traditional developers. They report greater job satisfaction, with 42% highly
satisfied versus only 31% of their peers. This suggests the market is already
rewarding those who leverage these tools strategically. Rather than commoditising
developer skills, the technology appears to be enabling a professional evolution
where developers shed tedious implementation work to focus on architecture,
strategy, and creative problem-solving.

Historical precedent offers another reason for optimism. When the Industrial
Revolution mechanised manufacturing, skilled artisans didn't simply disappear.
Instead, complexity migrated upward into new roles like factory managers, engineers,
and accountants. Similarly, as programming tasks become automated, the profession
isn't vanishing but polarising. The routine work gets handled by tools while
human expertise concentrates in higher-value activities like system design,
integration, and oversight. The modern developer becomes less of a "craftsman"
manually coding every detail and more of a "conductor" orchestrating complex systems.

The efficiency gains are undeniable. Low-code platforms can reduce development
time by 90% and cut costs by 70%. This isn't just about corporate profits.
It means businesses can ship products faster, respond to market needs more
quickly, and devote resources to innovation rather than maintenance. For
individual developers, 90% report having fewer than five application requests
in their backlog after adopting these tools, giving them breathing room to
tackle challenging, intellectually stimulating work rather than drowning
in routine requests.


### The Case for Concern

However, the critics of AI-assisted development raise serious concerns that can't
be dismissed as mere technophobia. Their central argument focuses on the erosion
of foundational knowledge. When developers consistently rely on high-level abstractions
and AI-generated code, they may never develop deep understanding of algorithms,
data structures, and system architecture. This creates what some call a "skill trap"
where practitioners become dependent on tools whose inner workings remain opaque to them.

The debugging problem illustrates this concern vividly. When you write your own code,
you possess an intuitive understanding of its logic and potential flaws. AI-generated
code, while often syntactically correct, can be semantically flawed in subtle ways.
It might reference outdated frameworks, fail to handle edge cases, or contain logical
errors that only manifest under specific conditions. Debugging shifts from a
self-contained process of logical deduction to troubleshooting an opaque black box.
A developer who never learned to reason about memory management or algorithm complexity
will struggle when the AI produces suboptimal code that causes performance bottlenecks
at scale.

Security presents another critical vulnerability. AI coding assistants, trained on vast
public repositories, can inadvertently reproduce known vulnerabilities from their
training data. They may fail to implement current security best practices or understand
the compliance requirements of regulated industries. A 2023 report revealed that over
half of organisations experienced security issues related to AI-generated code, and
87% of developers expressed concerns about its security implications. This isn't
hypothetical risk but documented reality.

The systemic implications are perhaps most troubling. Individual deskilling creates
collective vulnerability. If an entire generation of developers loses the ability to
reason about underlying systems, the technological infrastructure becomes fragile and
dependent on external, often proprietary, tools. When abstractions inevitably fail
or prove insufficient for novel problems, who will possess the foundational knowledge
to innovate? The concern isn't that AI will replace all developers but that it might
create a hollowed-out profession where a small elite understands the fundamentals
while most practitioners operate as mere tool users, unable to function when those
tools prove inadequate.

Education presents a particular challenge. Programming has traditionally had high
dropout rates precisely because concepts like pointers, data structures, and algorithm
analysis are difficult to learn. They require confronting mental challenges that
build deep problem-solving skills. By abstracting away these complexities, modern
tools make programming more accessible but may prevent students from ever developing
the very cognitive muscles that distinguish expert developers. The path of least
resistance leads to tool dependency rather than genuine mastery.


### Real-World Examples Illustrating Both Perspectives

Consider the example of database queries. An AI can generate a functional SQL query
that retrieves the data a developer needs. From the optimistic perspective, this is
pure efficiency gain. The developer gets working code in seconds rather than minutes
or hours, allowing them to move on to more strategic work. They can focus on designing
the overall data architecture or optimising the user experience rather than wrestling
with syntax.

From the critical perspective, however, that same scenario reveals a trap. The
AI-generated query might work perfectly with a small dataset but become a performance
disaster when the application scales. Without understanding database indexing, query
optimisation, and execution plans, the developer has no framework for evaluating whether
the solution is optimal. When users start complaining about slow load times months
later, the developer who copied the AI's solution lacks the knowledge to diagnose
why a seemingly functional query is now a bottleneck. They must either rely on the
AI again, hoping it can fix what it created, or escalate to a more senior developer
who still possesses foundational database knowledge.

Another illustrative case involves security vulnerabilities. An AI might generate
authentication code that appears to work correctly during testing. The optimistic
view celebrates this as democratising security implementation, making robust
authentication accessible even to junior developers. The critical view warns that
AI-trained on public code might reproduce common security anti-patterns, perhaps
storing passwords without proper hashing or failing to protect against SQL injection.
A developer without security fundamentals might deploy this code to production,
creating vulnerabilities that won't be discovered until an actual breach occurs.

The low-code platform example cuts both ways as well. A business analyst using a
low-code tool to build a departmental application without involving IT represents
efficiency from one angle and risk from another. The organisation gets its
application faster and cheaper, and the IT team avoids adding another small project
to their backlog. But that same application might lack proper error handling, fail
to meet data governance requirements, or create technical debt when it inevitably
needs to be integrated with enterprise systems. The initial efficiency gain could
transform into a maintenance nightmare.


### Synthesis and Path Forward

The debate ultimately isn't binary. Both perspectives capture genuine aspects of a
complex transformation. AI and automation tools are simultaneously empowering and
potentially deskilling, elevating the profession while creating new vulnerabilities.
The outcome depends less on the technology itself and more on how individuals
and organisations choose to adopt it.

The concept of "hybrid intelligence" offers perhaps the most promising framework.
Rather than viewing this as humans versus machines or even humans replaced by
machines, we might understand it as humans with machines achieving outcomes neither
could accomplish alone. In this model, AI handles routine implementation while
humans provide strategic direction, architectural vision, and the deep knowledge
needed when abstractions prove insufficient. The key is maintaining that deep
knowledge even while leveraging tools that make it less necessary for routine tasks.

This requires intentional effort. Educational institutions must teach both tool
proficiency and foundational principles, creating what might be called a "pedagogy
of contrast" where students learn to use modern frameworks but also understand
what those frameworks abstract away. Organizations must invest in continuous
upskilling, ensuring developers don't just learn new tools but maintain and
deepen their understanding of core computer science principles. Career paths
and job descriptions need reframing to reward strategic thinking and architectural
skill rather than just lines of code produced or years spent with specific
technologies.

The historical parallel to the Industrial Revolution remains instructive but
incomplete. Yes, complexity migrated upward into new skilled roles. But that
transition was neither automatic nor painless. It required deliberate investment
in education, new professional standards, and social structures to support the
transformation. The same intentionality is needed now. The question isn't
whether AI will deskill programming but whether we'll manage the transition
wisely, preserving and elevating essential human expertise even as we embrace
powerful new tools.


### The Question of Craft in Programming

Underlying much of this debate is a deeper question about what it means to
practice programming as a craft. The traditional notion of craftsmanship in
software development carries particular weight because it connects to ideals
of mastery, pride in one's work, and the satisfaction that comes from creating
something through skill and understanding rather than mere tool operation.

When we speak of programming as a craft, we typically invoke images of developers
who possess intimate knowledge of their tools and materials. Like a furniture maker
who understands wood grain and joinery, a craftsman programmer knows data structures
intimately, can reason about algorithm complexity without referring to documentation,
and writes code with an aesthetic sensibility that values elegance, efficiency,
and maintainability. This craftsperson takes pride not just in shipping working
software but in how that software is constructed. They read code the way a writer
reads literature, appreciating clever solutions and critiquing poor implementations.

The rise of AI assistance threatens this conception of craft in ways that parallel
broader anxieties about automation and meaningful work. If an AI can generate a
sorting algorithm or database query instantly, what happens to the satisfaction
of crafting such code yourself? When GitHub Copilot autocompletes entire functions,
does the developer become more akin to an assembly line worker overseeing machine
output rather than an artisan shaping raw materials? The concern isn't merely
about skill erosion but about the loss of something fundamentally human in the
work itself.

This perspective finds its strongest voice among experienced developers who
remember learning to program without such assistive tools. They recall the
satisfaction of finally understanding recursion after days of struggle, the pride
in optimising an algorithm to run twice as fast, the aesthetic pleasure of refactoring
messy code into something clean and readable. These experiences weren't just
educational, they were formative moments that built both competence and
professional identity. The fear is that a generation raised on AI assistance might
never experience these moments of genuine mastery, creating a profession
populated by people who can ship code but don't truly understand or take
pride in what they're creating.

There's also an argument that craft involves constraints. A poet working within
the structure of a sonnet or a painter limited to a specific palette might produce
more creative work precisely because of those limitations. The struggle with the
material, the need to work within boundaries, can paradoxically enhance creativity
and lead to more thoughtful solutions. When AI removes those constraints by
providing instant solutions, does it also remove the creative tension that produces
truly excellent code? The craftsperson perspective suggests that some friction
in the development process isn't just acceptable but necessary for producing
work of genuine quality and innovation.

Yet the counter-argument challenges whether we've been romanticising the
wrong aspects of the craft. Perhaps true craftsmanship in programming was
never really about writing every line of code by hand any more than a master
carpenter needs to forge their own nails or mill their own lumber. Instead, the
craft might lie in knowing which abstractions to use, how to compose complex
systems from simpler components, and when to create custom solutions versus
leveraging existing tools. From this perspective, AI assistance doesn't diminish
craft but elevates it to a higher level of abstraction.

Consider that we've already accepted many layers of abstraction without viewing
them as threats to craftsmanship. Few developers today would argue that writing
in assembly language is inherently more craftsman-like than using Python, even
though assembly requires more intimate knowledge of the hardware. We don't
consider it a loss of craft when a developer uses a well-tested sorting library
rather than implementing Quicksort from scratch. The craft has always been
about choosing the right level of abstraction for the problem at hand, and AI'
tools simply represent another step in that evolution.

This view suggests that craftsmanship in the AI age involves new skills that are no
less demanding than traditional coding. Crafting effective prompts to guide AI tools
requires deep understanding of what you're trying to achieve and how to communicate 
t clearly. Architecting systems that integrate AI-generated components demands
a macro-level design sense. Debugging and refining AI output calls for critical evaluation
skills and the ability to distinguish good code from merely functional code. These
are not lesser forms of craft but different expressions of the same fundamental
commitment to creating excellent software.

There's also an argument that fixating on the craft of individual code production
misses the larger picture. Software engineering has always involved trade-offs between
various goods: speed of delivery, maintainability, performance, security, cost.
A craftsperson who spends days handcrafting an elegant solution to a problem that
an AI could solve adequately in minutes might be indulging in a form of self-satisfaction
that doesn't serve the actual needs of users or organisations. The true craft might
lie in making wise judgments about when to leverage automation and when to invest
in custom solutions, not in reflexively choosing the path that feels more
traditionally artisanal.

However, this purely pragmatic view may underestimate the human psychological needs
that craft fulfils. Research on job satisfaction consistently shows that people
derive meaning from work where they can see the direct connection between their
skills, their effort, and tangible outcomes. If a developer's role becomes primarily
supervisory, reviewing and integrating code they didn't create, that sense of direct
authorship and accomplishment may diminish. This isn't just nostalgia or resistance
to change but a legitimate concern about what makes work psychologically sustaining
over a career.

The craft question also intersects with concerns about professional identity
and community. Programming culture has long celebrated certain values: elegance
in implementation, cleverness in problem-solving, deep technical knowledge.
Code reviews, technical discussions, and mentorship relationships all depend
on shared understanding of what constitutes good work. If AI tools reduce
programming to prompt engineering and integration work, does the community
lose shared touchstones for evaluating expertise? How do you mentor someone
in a craft when the actual creation is delegated to an AI?

Yet defenders of AI assistance point out that craft communities have always evolved
their standards and practices in response to new tools and methods. Oil painters
didn't abandon their craft when synthetic pigments replaced hand-ground minerals.
Jazz musicians didn't stop being craftspeople when electronic instruments expanded
their palette. Perhaps programming craft will similarly adapt, developing new
aesthetic criteria and technical standards appropriate to an AI-augmented world.
The next generation might take pride in the elegance of their system architectures
or the cleverness of their prompt engineering rather than the beauty of their
manually written algorithms, and this might be no less valid as an expression of craft.


### Synthesis and Path Forward

The debate ultimately isn't binary. Both perspectives capture genuine aspects of a
complex transformation. AI and automation tools are simultaneously empowering and
potentially deskilling, elevating the profession while creating new vulnerabilities.
The outcome depends less on the technology itself and more on how individuals
and organisations choose to adopt it.

The concept of "hybrid intelligence" offers perhaps the most promising framework.
Rather than viewing this as humans versus machines or even humans replaced by machines,
we might understand it as humans with machines achieving outcomes neither could
accomplish alone. In this model, AI handles routine implementation while humans
provide strategic direction, architectural vision, and the deep knowledge needed
when abstractions prove insufficient. The key is maintaining that deep knowledge
even while leveraging tools that make it less necessary for routine tasks.

This requires intentional effort. Educational institutions must teach both tool
proficiency and foundational principles, creating what might be called a "pedagogy
of contrast" where students learn to use modern frameworks but also understand
what those frameworks abstract away. Organizations must invest in continuous
upskilling, ensuring developers don't just learn new tools but maintain and
deepen their understanding of core computer science principles. Career paths
and job descriptions need reframing to reward strategic thinking and architectural
skill rather than just lines of code produced or years spent with specific
technologies.

The historical parallel to the Industrial Revolution remains instructive but
incomplete. Yes, complexity migrated upward into new skilled roles. But that
transition was neither automatic nor painless. It required deliberate investment
in education, new professional standards, and social structures to support the
transformation. The same intentionality is needed now. The question isn't whether
AI will deskill programming but whether we'll manage the transition wisely, 
reserving and elevating essential human expertise even as we embrace powerful
new tools.


### Discussion Topics for Reflection

Now that you've explored the various dimensions of deskilling, automation, and
craftsmanship in programming, it's worth engaging more deeply with these ideas
through critical reflection. The following topics are designed to help you think
through the tensions and complexities we've examined, connecting them to your
own experiences and aspirations as a developer or student of computer science.

__On Historical Patterns and Future Trajectories__: The Industrial Revolution
displaced skilled artisans but created new professional classes of engineers,
managers, and technicians. The document argues that programming is undergoing
a similar polarisation rather than simple elimination. But consider whether
this historical parallel holds up under scrutiny. Are there important differences
between physical manufacturing and knowledge work that might make the analogy
break down? When complexity "migrated upward" during industrialisation, it
took generations and involved significant social upheaval. What does this
suggest about the pace and pain of the current transition? You might also
consider whether the concentration of expertise in fewer hands represents
genuine progress or creates new forms of inequality and vulnerability in the
technology sector.

__On the Security Paradox__: The text highlights that AI-generated code can
reproduce known vulnerabilities and fail to implement current security best
practices, with over half of organisations experiencing security issues from
AI code. Yet these same tools are marketed as making secure development more
accessible. How do you reconcile this tension? Is it possible that AI tools
make security both better and worse simultaneously, perhaps securing routine
cases while creating new vulnerability patterns? Think about who bears
responsibility when AI-generated code causes a security breach. Should it be
the developer who accepted the suggestion, the company that deployed it, or
the AI tool provider? This question touches on broader issues of accountability
in increasingly automated systems.

__On the Nature of Understanding__: A central concern in the deskilling debate
is whether developers using high-level abstractions and AI assistance truly
understand what their code does. But what does "understanding" mean in this
context? When you use a sorting library, do you need to understand the specific
algorithm it implements, or is it sufficient to understand its time complexity
and when to use it? Where do you draw the line between acceptable abstraction
and dangerous ignorance? Consider also that expert developers routinely use
tools and libraries whose internals they don't fully understand. Is there a
meaningful difference between relying on a well-established library and relying
on AI-generated code, or is this distinction somehow arbitrary?

__On Craftsmanship and Meaning__: The section on craft explores whether programming
is losing something essential when AI automates code creation, or whether craft
is simply evolving to a higher level of abstraction. Reflect on your own experience
with programming. Do you find satisfaction in the act of writing code itself, or
primarily in solving problems and creating functional systems? If you've used AI
coding assistants, did they enhance or diminish your sense of accomplishment?
Think about what makes work meaningful to you. Is there something intrinsically
valuable about the struggle to implement a solution from scratch, or is this a
form of unnecessary difficulty that we should be happy to automate away? How
might your answer change if you were working under deadline pressure versus
learning for personal growth?

__On the Education Dilemma__: The document proposes a "pedagogy of contrast" where
students learn both modern tools and foundational principles. But this approach
assumes students have time and motivation to learn both. In reality, students
face pressures to become job-ready quickly and may question why they should learn
"outdated" skills when AI can handle them. How would you respond to a fellow
student who asks why they should spend weeks mastering data structures and
algorithms when they can just prompt an AI to generate efficient code? Is there
a way to make the case for foundational knowledge that goes beyond appeals to
professional virtue or warnings about hypothetical future scenarios? Consider
also whether educational institutions can realistically teach everything, or
whether we need to accept that some knowledge will be lost as new skills
become necessary.

__On Market Signals and Professional Evolution__: The evidence shows that
developers who adopt low-code platforms earn higher salaries and report
greater job satisfaction. This suggests the market is rewarding tool adoption
and strategic thinking over traditional coding skills. Yet the document also
warns about erosion of foundational expertise. How do you navigate this tension
in planning your own career? Should you focus on learning the tools and
approaches the market currently rewards, even if they might contribute to
long-term deskilling? Or should you invest in deep foundational knowledge
that might be less immediately marketable? Think about whether it's possible
to pursue both paths simultaneously, and what trade-offs you might need to
accept. Consider also whether early-career developers face different incentives
than experienced professionals, and whether the optimal strategy changes over
the course of a career.

__On System-Level Fragility__: The text argues that individual deskilling creates
collective vulnerability, making entire technological infrastructures dependent
on external tools and the small elite who understand foundational principles.
But is this necessarily bad? Modern society depends on countless systems that
few people understand completely, from electrical grids to pharmaceutical
supply chains. We've developed institutional structures, regulations, and
professional standards to manage these dependencies. Could similar structures
work for programming? Or is there something uniquely dangerous about deskilling
in software development? Think about what happens when abstractions fail or
prove insufficient for novel problems. Who will have the knowledge to innovate?
Is it realistic to expect most developers to maintain deep foundational knowledge
they rarely use, or should we accept a more specialised profession where different
tiers have different depths of understanding?

__On the Citizen Developer Phenomenon__: Low-code platforms are enabling "citizen
developers" with minimal coding experience to build applications, and they're
projected to outnumber professional developers four to one. Some see this as
democratisation of technology, others as a quality and security disaster waiting
to happen. Where do you stand? Consider the analogy to other fields. Desktop
publishing tools allowed non-designers to create documents, sometimes with
terrible results but also democratising access to design capabilities. Personal
finance software enables people to manage investments without professional
financial advisors, with mixed outcomes. What makes programming similar to or
different from these cases? Think about whether there are certain types of
applications that citizen developers should absolutely not build, or whether
with proper guardrails and templates, they can safely handle more than skeptics
believe.

__On Debugging as the Core Skill__: Several sections emphasise that debugging
AI-generated code requires different and perhaps more sophisticated skills than
debugging code you wrote yourself. You must understand the context, dependencies,
and potential failure modes of code whose internal logic you didn't design. Is
debugging, rather than creation, becoming the central skill of modern programming?
If so, what does this mean for how programming should be taught? Should curricula
focus more on reading and analysing existing code rather than writing from scratch?
Consider your own experience with debugging. What makes it difficult? Is it
harder to debug code you didn't write, code written in an unfamiliar style,
or code whose purpose you don't fully understand? How might these challenges
multiply when the code comes from an AI that doesn't explain its reasoning?

__On the Definition of Senior Developer__: The document suggests we need to redefine
what "senior" means in programming, shifting from years of experience with specific
technologies to strategic architectural thinking. But how do you evaluate and
credential these higher-order skills? It's relatively easy to test whether someone
can implement a binary search tree or knows the syntax of a particular language.
It's much harder to assess whether they have good architectural judgment or can
effectively prompt and validate AI systems. How should organisations and the
profession more broadly handle this transition? Should certifications and interviews
change? What about mentorship relationships, when the mentor's deep coding knowledge
may be less relevant but their strategic thinking is hard to transfer? Think about
what you would want from a senior developer on your team. Would you prefer someone
with deep technical knowledge who can dive into complex debugging, or someone with
broad architectural vision who might rely more on tools for implementation?

__On Personal Agency and Skill Investment__: Ultimately, each developer must make
individual choices about which skills to develop and which tools to adopt. The
document presents both opportunities and risks, but you must navigate these fo
yourself. How do you decide whether to lean heavily into AI assistance or maintain
a more traditional skill set? What role does personal interest versus market
pragmatism play in your decision? Consider that your choices don't just affect
your own career but collectively shape the profession's future. If everyone chooses
short-term efficiency over foundational knowledge, the collective outcome might b
professional deskilling. If everyone insists on mastering low-level details that
AI can handle, the profession might become inefficient and fail to meet market
needs. How do you balance personal optimisation with collective professional
health? Is this even your responsibility, or should you focus purely on your
own career success and let broader trends take care of themselves?

These topics don't have simple right answers. They're meant to help you engage critically
with the transformations happening in programming and think through their implications for
your own learning and career. The tensions they explore, between efficiency and expertise,
between democratisation and quality, between adaptation and preservation, will likely
define the programming profession for years to come. Your thoughtful engagement with
these questions will help you navigate this evolving landscape more intentionally and
perhaps contribute to shaping it in positive directions.


